# ğŸ“š Book Scraper Pipeline

This project demonstrates a simple data engineering pipeline that extracts book data from [Books to Scrape](http://books.toscrape.com/), transforms it, and loads it into a SQLite database.

---

## ğŸš€ Project Overview

**Goal:** Build a basic ETL pipeline using Python to:
- ğŸ§© **Extract** book data (title, price, rating) via web scraping
- ğŸ§¼ **Transform** the data (clean/format it using pandas)
- ğŸ—ï¸ **Load** it into a SQLite database

---

## ğŸ› ï¸ Tech Stack

| Task         | Tools Used           |
|--------------|----------------------|
| Scraping     | `requests`, `BeautifulSoup` |
| Transformation | `pandas` |
| Storage      | `SQLite` (`sqlite3`) |
| Environment  | `virtualenv` + `pip` |

---

## ğŸ“ Project Structure
book-scraper-pipeline/
â”œâ”€â”€ data/                  # store raw or cleaned data
â”œâ”€â”€ src/                   # all Python code goes here
â”‚   â”œâ”€â”€ scrape.py
â”‚   â”œâ”€â”€ clean.py
â”‚   â””â”€â”€ load.py
â”œâ”€â”€ main.py                # runs the full pipeline
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ“¦ Setup Instructions

### 1. Clone the repository
```
git clone https://github.com/htthuyen/book-scraper-pipeline.git
cd book-scraper-pipeline
```
### 2. Create and activate a virtual environment
```
python -m venv myenv
source myenv/bin/activate
```
### 3. Install dependencies
```
pip install -r requirement.txt
```

## ğŸ§ª How to Run the Pipeline
```
python main.py
```

